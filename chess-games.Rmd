---
title: "Chess games analysis"
output: html_notebook
---

## About the dataset

The chosen dataset concerns over 20 000 games played on the popular online chess website [Lichess](https://lichess.org). It contains both qualitative and quantitative data and lends itself to many forms of analysis and study. The dataset itself comes from [kaggle](https://www.kaggle.com/datasnaek/chess).

The following variables are of use to me:

- Turns: the number of turns (double the number of moves) it took for the game to end, a quantitative variable (continuous integers)
- Victory status: the type of event that concluded the match, a qualitative variable
- Winner: the colour of the winning party, a qualitative variable
- Increment code: type of game-time incrementation used, a qualitative variable
- White/Black rating: Lichess ([Glicko-2](https://www.glicko.net/glicko/glicko2.pdf)) rating based on user's ranked game history, a quantitative variable (continuous integers)
- Opening eco: the chess opening code for a given opening, a qualitative variable
- Opening ply: the number of moves in the opening phase, a quantitative variable (continuous integers)

There are a few more variables that I have chosen to ignore:

- ID: game id in the Lichess games system/database
- Rated: boolean value describing whether the game had an impact on player rating or not
- Created/last move at: times at which a game started and when the last move was made before the game ended
- Moves: list of moves made during the game in standard chess notation, processing them could be interesting for those studying the games or players themselves
- Opening name: as I already have the more general opening code, opening names will just introduce more unique variables when factoring in variations of openings, which is harder to work with

## Initial analysis - data visualisation

To make the data-set more approachable, I conducted some visualisations to better understand the type and layout of the data I am working with. Initial visualisations can help give us clues about how to process the data later on, or what calls for further and more detailed analysis.

There are no missing values in the data set, therefore no additional processing is needed.

```{r message=FALSE, warning=FALSE}
library(ggplot2) #graphs
library(ggcorrplot)
library(tidyverse) # various tools
library(tidyr)
library(dplyr)
library(reshape2)
library(formattable)
library(caret) # required for test and training set
library(MLmetrics)
games <- read.csv("games.csv", header=T, stringsAsFactors=T)
```

### Visualising the amount of turns

```{r}
ggplot(games, aes(turns)) + geom_histogram(aes(y=..density..), binwidth=15, fill="salmon1", color="black") + ggtitle("Distribution of turn counts") + xlab("Turn count") + ylab("Density of games") + geom_density(color="salmon4", alpha=.5, size=1)
```

The game turns histogram looks ordinary. It is right-skewed (positive skew) and the average turn count seems to be withing the fifties. In fact, this somewhat corresponds to data by [chessstats](https://www.chessgames.com/chessstats.html), which states that average number of moves per game is about 41, although it is still quite a bit higher.

### Visualising the ratings

As the most optimal opponent range has a rating of +/- 100 to 150, I have chosen a bin size of 100 for the ratings histogram.

```{r}
ggplot(games, aes(x=white_rating)) + geom_histogram(aes(y=..density..), binwidth=100, fill="skyblue1", color="black") + ggtitle("White rating density") + xlab("Rating") + ylab("Density of players") + geom_density(color="royalblue4", alpha=.5, size=1)
ggplot(games, aes(x=black_rating)) + geom_histogram(aes(y=..density..), binwidth=100, fill="indianred1", color="black") + ggtitle("Black rating density") + xlab("Rating") + ylab("Density of players") + geom_density(color="firebrick4", alpha=.5, size=1)
```

When a user first registers on Lichess, their rating starts at 1500 (+/- 700). The 1500 represents their rating and the 700 represents the confidence interval. This is because an average club player is rated 1500, which is around the 50th percentile for every variant and time control in chess.

It is thus unsurprising that both white and black ratings peak at around 1500. The ratings seem to be slightly right-skewed, which also makes sense, as usually the higher rated a player is, the more invested they are in the game. This in turns means that they play more and are thus more likely to be playing ranked games on Lichess.

#### Comparing the ratings

```{r}
ggplot(games) + geom_histogram(aes(x=white_rating), binwidth=100, fill="skyblue1", color="black", alpha=0.6) + geom_histogram(aes(x=black_rating), binwidth=100, fill="indianred1", color="black", alpha=0.6) + ggtitle("Comparing ratings") + xlab("Ratings") + ylab("Number of players")
```

We can see that the ratings for both white and black are mostly overlapping. This does not come as a surprise as a player should be able to play both as white and as black, and therefore would have comparable ratings for both of those colours. Interestingly enough, it would seem that there are slightly higher ratings for white, as the level of game increases, while black ratings seem to have a minimal edge for lower ranked players.

### Visualising game outcomes

```{r}
options(dplyr.summarise.inform=F)
win_counts <-group_by(games, winner) %>% summarise(Count=n()) %>% arrange(desc(Count))
ggplot(win_counts, aes(x="", y=Count, fill=winner)) + geom_bar(stat="identity", width=1, color="black") + coord_polar("y", start=0) + theme_void() + ggtitle("Game outcome") + theme(legend.title=element_blank()) + scale_fill_manual(values=c("grey21", "grey61", "grey91"))
```

The fact that white has a slightly higher probability to win a game is known as the [first move advantage](https://en.wikipedia.org/wiki/First-move_advantage_in_chess) and is most common for lower ranked players, where that advantage is harder to make up for with the lack of theoretical knowledge and experience.

I am however surprised to see that there aren't more draws, but this may be due to the fact that lower level players have less of a apacity to evaluate a board and conclude a draw.

#### Visualising game ending reasons

```{r}
options(dplyr.summarise.inform=F)
victory_status <- group_by(games, victory_status) %>% summarise(Count=n()) %>% arrange(desc(Count))
ggplot(victory_status, aes(x="", y=Count, fill=victory_status)) + geom_bar(stat="identity", width=1, color="black") + coord_polar("y", start=0) + theme_void() + ggtitle("Game end status") + theme(legend.title=element_blank()) + scale_fill_manual(values=c("skyblue1", "indianred1", "grey91", "lightsalmon1"))
```

We can see that in most cases, the game ended due to one party resigning. This is unsurprising as in chess, especially in higher levels, a player will often resign when they see that their position is irrecoverable.

It is worthy to note that games that ended due to lack of time most likely also encompass games where one player abandoned the game without resigning. Such games then ended when the timer reached 0. The basis for my reasoning is that in longer time controls, losing due to time running out is not so likely, especially if we consider the relative size to game ends by draw.

However, we could get a clearer idea of the game end statuses if we pair them with the average number of turns made in the game.

```{r}
options(dplyr.summarise.inform=F)
victory_status_avg <- group_by(games, victory_status) %>% summarise(Mean=mean(turns)) %>% arrange(desc(Mean))
ggplot(victory_status_avg, aes(x="", y=Mean, fill=victory_status)) + geom_bar(stat="identity", width=1, color="black") + coord_polar("y", start=0) + theme_void() + ggtitle("Game end status by average number of turns") + theme(legend.title=element_blank()) + scale_fill_manual(values=c("skyblue1", "indianred1", "grey91", "lightsalmon1"))
```

It would seem that as games drag out, draws become more common. This could be due to player-agreed draw, or automatic draw such as [threefold repetition](https://en.wikipedia.org/wiki/Threefold_repetition). It would also seem that losing due to time becomes also far more common, thus refuting my previous proposition that players abandoned the game but didn't resign.

#### Visualising openings

```{r}
black_wins <- subset(games, winner=="black") %>% group_by(opening_eco) %>% summarise(Count=n()) %>% arrange(desc(Count))
white_wins <- subset(games, winner=="white") %>% group_by(opening_eco) %>% summarise(Count=n()) %>% arrange(desc(Count))

white_wins$percentage <- white_wins$Count / nrow(subset(games, winner=="white"))
black_wins$percentage <- black_wins$Count / nrow(subset(games, winner=="black"))

ggplot(white_wins[1:7,], aes(x=opening_eco, y=percentage)) + geom_bar(stat = "identity", fill=c("#7d87b9", "#8dd593", "#bb7784", "#e6afb9", "#e07b91", "#f0b98d", "#9cded6"), alpha=1) + ggtitle("Top 7 openings for white by win percent") + xlab("ECO opening code") + ylab("Percentage (out of 1)")

ggplot(black_wins[1:7,], aes(x=opening_eco, y=percentage)) + geom_bar(stat = "identity", fill=c("#8dd593", "#7d87b9", "#f0b98d", "#8595e1", "#e07b91", "#d6bcc0", "#8491b4b2"), alpha=1) + ggtitle("Top 7 openings for black by win percent") + xlab("ECO opening code") + ylab("Percentage (out of 1)")
```

A00 stands for ["Uncommon chess opening"](https://www.chessgames.com/perl/chessopening?eco=a00) and it is seemingly very profitable for both white and black. This however shouldn't be interpreted as "I can start however I want, and I will win", because simply because the majority of openings themselves are uncommon:

```{r}
top_openings <- games %>% group_by(opening_eco) %>% summarise(Count=n()) %>% arrange(desc(Count))
ggplot(top_openings[1:7,], aes(x=opening_eco, y=Count)) + geom_bar(stat = "identity", fill=c("#8dd593", "#7d87b9", "#f0b98d", "#e07b91", "#bb7784", "#8595e1", "#9cded6"), alpha=1) + ggtitle("Top 7 openings by count") + xlab("ECO opening code") + ylab("Count")
```

## Quantitative overview

We can now more closely examine our quantitative variables: the amount of turns, white/black ratings, and the amount of moves in the opening phase of a game.

Helper functions:

```{r}
mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

trimean <- function(x) {
  quartiles <- quantile(x, prob=c(.25,.5,.75))
  q1 <- quartiles[1]
  q2 <- quartiles[2]
  q3 <- quartiles[3]
  (q1 + 2 * q2 + q3) / 4
}

gm_mean = function(x) {
  exp(sum(log(x[x > 0])) / length(x))
}

rel_range = function(x) {
  max(x) - min(x)
}

iqr = function(x) {
  quartiles <- quantile(x, prob=c(.25,.5,.75))
  quartiles[3] - quartiles[1]
}
```

```{r}
add_quant <- function(x, y, z) {
  dig <- 2
  x %>% add_row(Name = z, Mean = round(mean(y), digits=dig), Median = round(median(y), digits=dig), Mode = round(mode(y), digits=dig), Trimean = round(trimean(y), digits=dig), "Geometric mean" = round(gm_mean(y), digits=dig), Range = round(rel_range(y), digits=dig), IQR = round(iqr(y), digits=dig), Variance = round(var(y), digits=dig), "Standard deviation" = round(sd(y), digits=dig))
}

quant_names <- c("Mean", "Median", "Mode", "Trimean", "Geometric mean", "Range", "IQR", "Variance", "Standard deviation");

quant_overview <- data.frame(matrix(ncol=9, nrow=0));
names(quant_overview) <- quant_names
quant_overview <- rownames_to_column(quant_overview, var = "Name")

quant_overview <- add_quant(quant_overview, games$turns, "Rounds")
quant_overview <- add_quant(quant_overview, games$white_rating, "White rating")
quant_overview <- add_quant(quant_overview, games$black_rating, "Black rating")
quant_overview <- add_quant(quant_overview, games$opening_ply, "Opening moves")

formattable(quant_overview)
```

The mode tells us that the most common rating for both white and black is 1500. This makes sense as it is the default rating given to a user by Lichess upon creating an account. If a user never plays ranked matches, their rating will stay at 1500 until they play ranked matches. It seems that on average, players have slightly higher ratings as white (hence win more games as white) which again correlates to the first move advantage present in chess.

From the range we can see that there are both very highly rated players on Lichess, hence probably some international and grandmasters, as well as players who should probably rethink their approach to playing and studying chess, as their low ratings point to them losing most of the games they play against opponents of presumably comparable ratings.

The standard deviation is not very high either if we factor in the nature of the Glicko scale, and how easy it is to move up or down in ratings within the 1200-1700 rating range, after first joining Lichess (due to off-platform proficiency). It would seem that the average player is however rated slightly more than the Lichess default of 1500, and player ratings do not deviate remarkably far from that average.

We can see that half of games played aren't longer than 55 turns, with the most games lasting for 53 turns. Interestingly, the average number of turns of a game is 60.47 which would suggest that there is a non negligible amount of games that dragged on for large numbers of turns.

While in chess the shortest mates are the [Fool's Mate](https://en.wikipedia.org/wiki/Fool%27s_mate) (2 turns) and the [Scholar's Mate](https://en.wikipedia.org/wiki/Scholar%27s_mate) (4 turns), a game can of course consist of only one turn in case of running out of time, or an immediate resign. As the range of turns is 348, we can deduce that there is at least one game with 349 turns, which solidifies our previous theory of some games reaching high turn counts.

Concerning the opening moves, it seems that on average, almost 5 moves are played by the book, but most commonly, no more than 3 moves are from book opening variations. It is a bit surprising that the number is so low, as most opening theory covers way more moves, but as there aren't only club/pro players on Lichess, it makes sense that standard openings aren't followed by the book as often. The standard deviation is not very high, showing that most games fall have opening falls within three moves of the average number of moves in the opening phase.

In conclusion we can say that the Lichess games data set is not very surprising, if one factors in the fact that both hobby or even rookie players, and club or even master players can be found on the platform. Of course such mishmash will provide deviations from chess statistics from tournament and club games, but it's a wonderful way to show the broad appeal and various approaches that the game has.

The quantitative overview of variables corresponds very well to the initial visualisations of the data set, with no deviations worthy of concern.

## Examining relationships

From what we saw from the initial visualisation stage, we can assume that white and black ratings are somewhat related to each other. Furthermore, it seems logical that the opening and the number of moves in the opening phase would have at least minor correlations due to the length, popularity and variation count factors of openings. Finally we can also suppose that the qualitative id's for white and black have some form of relationship as we can expect players to replay each-other a number of times.

It would be interesting to see if players of certain ratings have a preference for the games' time control, and if the opening favors a side in winning (consistency with opening book theory).

### Correlation matrices

```{r}
char2num<-function(x) { 
  groups = unique(x) 
  as.numeric(factor(x, levels=groups)) 
}

matrix_data <- subset(games, select = c(turns, white_rating, black_rating, opening_eco, opening_ply, increment_code, winner, white_id, black_id))
matrix_data$opening_eco <- char2num(matrix_data$opening_eco)
matrix_data$increment_code <- char2num(matrix_data$increment_code)
matrix_data$winner <- char2num(matrix_data$winner)
matrix_data$white_id <- char2num(matrix_data$white_id)
matrix_data$black_id <- char2num(matrix_data$black_id)

corr <- cor(matrix_data)
ggcorrplot(corr, lab=T)
```

#### How to read the correlation matrix

The above correlation matrix gives us Pearson correlation coefficients, which is a way to measure the linear relationship between two variables. This value appears in the interval [-1;1], where the further the coefficient is from 0, the stronger the relationship between variables is. A positive coefficient indicates a positive correlation, and vice versa for a negative coefficient.

#### Notable correlations

We can see that white's and black's rating seems to be in correlation, which confirms what we saw from our initial visualisations. Indeed, players of similar ratings are paired together for random ranked games on Lichess. While the correlation is not as strong as I would have expected, I suspect that the reason for this is that a player can still play another player of any ranking, as there are no rules determining the maximum rating gap between players.

Furthermore, black's and white's id's have a very strong correlation, which confirms that many players tend to play more than one game against one another. However, as those are qualitative variables, it is difficult to visualise their relationship on a graph, instead, a contingency table should be used.

Finally, we can see a non negligible correlation between the chosen opening and the number of moves played in the opening phase. Likewise, as these variables are qualitative, visualising them on a graph is not feasible.

I am somewhat surprised that there seems to be a total absence of correlation between the number of turns and the opening, as some openings are more aggressive/sharp, while others are more passive, potentially leading to slow and complex middle- and endgames.

As qualitative variables are best suited for classification and not regression, I won't be treating them in this project.

### Dependent and independent variable relationships

#### White and black ratings

```{r}
ratings_matrix <- subset(games, select = c(white_rating, black_rating))
ggplot(ratings_matrix, aes(x=white_rating, y=black_rating)) + geom_point(color="royalblue4") + ggtitle("Relationship of white and black ratings") + xlab("White rating") + ylab("Black rating")
```

Let's try to avoid overplotting, I round the ratings to the nearest multiple of 25, which isn't a huge gap to close for players with ratings lower than 2200. Players above that are scarcer in any case, and their games are less likely to be against opponents of same ratings on Lichess.

```{r}
ratings_matrix$white_rating <- round(ratings_matrix$white_rating/25)*25
ratings_matrix$black_rating <- round(ratings_matrix$black_rating/25)*25
ggplot(ratings_matrix, aes(x=white_rating, y=black_rating)) + geom_point(alpha=1/4, color="royalblue4") + ggtitle("Relationship of white and black ratings") + xlab("White rating") + ylab("Black rating")
```

There seems to be somewhat of a linear relationship between the ratings, however there is a large spread and most likely the error margin is quite big. Furthermore, there are quite a few outlier relationships, however these aren't prominent enough to affect most regression models.

There seems to be a high rate of both white and black 1500 rated players who are playing much further out of their rating bracket than the standard. I assume this is due to people who "know their level" and manually seek out higher rater players in order to more quickly climb the Lichess rating ranks. This pehnomenon can be spotted by the cross formed by x = 1500 and y = 1500.

### Regression models

#### Linear regression

Since there is only one quantitative linear correlation, I will have to work with the white and black ratings relationship. I will work on the overplotting-adapted data.

```{r}
ggplot(ratings_matrix, aes(x=white_rating, y=black_rating)) + geom_point(alpha=1/4, color="royalblue4") + ggtitle("Linear regression model") + xlab("White rating") + ylab("Black rating") + geom_smooth(method="lm", formula=y~x, color="firebrick1")
```
We can see that the linear regression model does not do a very good job at matching ratings, and thus would not be very suitable for any forms of interpolation or extrapolation. This is most likely due to partly the specificity of the Lichess data, that doesn't exactly map to competitive chess, but also due to the complexity of the rating model itself.

In fact, as the higher one ranks on the Glicko scale, the harder it is to progress further up, and the easier it is to fall down, even simply drawing a few games could result in a drastic drop in rating, while a small improvement would only result from winning a few elite level games.

Due to this, I suspect that alternative regression models should be used for predicting and mapping the relationship between ratings. In fact, I would guess that a logistic regression model would do a much better job at matching the graph.

#### Generalised linear model

#### Poisson regression

```{r}
ggplot(ratings_matrix, aes(x=white_rating, y=black_rating)) + geom_point(alpha=1/4, color="royalblue4") + ggtitle("Poisson regression model") + xlab("White rating") + ylab("Black rating") + geom_smooth(method="glm", formula=y~x, color="firebrick1", method.args=list(family="poisson"))
```

It isn't perfect yet but it seems to fit better. We can see that the curve is slightly more accurate in following the plot.

#### Logistic regression

```{r}
ggplot(ratings_matrix, aes(x=white_rating, y=black_rating)) + geom_point(alpha=1/4, color="royalblue4") + ggtitle("Logistic regression model") + xlab("White rating") + ylab("Black rating") + geom_smooth(method="glm", formula=y~x, color="firebrick1", method.args=list(family="binomial"))
```

NOTICE: So there is no model drawn on it? Why? Because R won't accept the "binomial" parameter for my data set.

Now I truly believe this model would be quite a nice fit, however I simply cannot seem to find a way to debug the R error that causes the regression computation to fail. This issue is present also later in the training phase. No solutions from the web have helped.

#### Alternative regression models

Since plotting / graphing many of these alternative models are complex and require a package cluster-mess, I will simply describe them here, and will use them more extensively when training and testing different regression models, for practical reasons.

##### Boosting algorithms

Boosting algorithms are a class of algorithms that can convert "weak learners" to "strong learners". In essence, if decision rules individually aren't descriptive enough to correctly predict / classify data, the set of rules is called a weak learner. A strong learner results from the combination of predictions of weak learners using methods such as the average/weighted average.

###### Stochastic gradient boosting

Gradient boosting algorithms consist of a loss function, a weak learner and an additive model (new regression trees are added, existing models remain unchanged). THe algorithm then tries to add trees to the weak learner while minimising the loss. The new models are then added to existing ones to correct/improve the underlying model.

Stochastic gradient boosting is a variation of gradient boosting where new trees are created from subsamples of the training dataset, analogous to bagging.

###### eXtreme gradient boosting

Extremeness consists in more aggressive sub-sampling. For example, selecting only 50% as a subsample.

##### K-nearest neighbours

The k-nearest neighbors (KNN) algorithm assumes that similar things exist in close proximity. In other words, it locates and calculates the proximity between training data and new data. From those k-neighbours, in the case of regression, it returns the mean of the best matches.

##### Classification and regression trees

CART models function based on binary trees. Suitable points in the data are used to split the data and construct the tree which has the goal of minimising a certain cost metric/function.

##### Support Vector Machines

In SVM models, data items are plotted in an n-dimensional space (n is the number of features) and each value will thus be a coordinate. Then the algorithm tries to find a hyperplane (in the n-dimensional space) that separates two label classes. It is mostly used for classification, but is also becoming more popular for regression: Support Vector Regression (SVR).

## Training and testing regression models

### Choosing and splitting the dataset

I have chosen to train the model on 80% of of the data set, which leaves 20% for testing.

```{r}
relevant_data <- subset(games, select = c(white_rating, black_rating))
sample <- createDataPartition(relevant_data$white_rating, p=.8, list=F)

#$white_rating <- as.factor(relevant_data$white_rating)
training <- relevant_data[sample,]
testing <- relevant_data[-sample,]

#training <- data.frame(training)
```

### Training regression models on the training set

I will be using k-fold cross validation method when training my models, which involves splitting the dataset into k-subsets called folds. All k-1 folds will then be trained/analysed and the analysis is then validated on the remaining subset. This process is repeated until each fold has been a test subset, and the overall prediction accuracy can then be estimated by computing the average of the k recorded errors.

```{r message=FALSE, warning=FALSE}
tc <- trainControl(method="cv", number=10)
set.seed(123)

lm_mod <- train(white_rating ~ ., data=training, method="lm", trControl=tc)
poisson_mod <- train(white_rating ~ ., data=training, method="glm", trControl=tc, family=poisson)
cart_mod <- train(white_rating ~ ., data=training, method="rpart", trControl=tc)
ext_mod <- train(white_rating ~ ., data=training, method="xgbLinear", trControl=tc)
brnn_mod <- train(white_rating ~ ., data=training, method="brnn", trControl=tc)
gbm_mod <- train(white_rating ~ ., data=training, method="gbm", trControl=tc)
knn_mod <- train(white_rating ~ ., data=training, method="knn", trControl=tc)
rlm_mod <- train(white_rating ~ ., data=training, method="rlm", trControl=tc)

# Commented out trainings that caused unexpected R errors that I haven't been able to debug
#glm_mod <- train(white_rating ~ ., data=training, method="randomGLM")
#lmt_mod <- train(white_rating ~ ., data=training, method="LMT")
# Quantile regression neural network
#qrnn_mod <- train(white_rating ~ ., data=training, method="qrnn")
# Neural net
#neural_mod <- train(white_rating ~ ., data=training, method="neuralnet")
# Lasso
#lasso_mod <- train(white_rating ~ ., data=training, method="lasso")
# Ridge regression
#ridge_mod <- train(white_rating ~ ., data=training, method="ridge")
# Elasticnet
#enet_mod <- train(white_rating ~ ., data=training, method="enet")
```

### Testing the models

```{r}
metric_names <- c("R2", "RMSE", "MAE", "MAPE", "MSE");
model_metrics <- data.frame(matrix(ncol=5, nrow=0));
names(model_metrics) <- metric_names
model_metrics <- rownames_to_column(model_metrics, var = "Metric name")

add_mm <- function(x, y) {
  predictions <- x %>% predict(testing)
  dig <- 2
  model_metrics %>% add_row("Metric name" = y, R2=R2(predictions, testing$white_rating), RMSE=RMSE(predictions, testing$white_rating), MAE=MAE(predictions, testing$white_rating), MAPE=MAPE(predictions, testing$white_rating), MSE=MSE(predictions, testing$white_rating))
}


model_metrics <- add_mm(lm_mod, "Linear regression model")
model_metrics <- add_mm(poisson_mod, "Poisson regression model")
model_metrics <- add_mm(brnn_mod, "Bayesian regularised neural networks")
model_metrics <- add_mm(ext_mod, "eXtreme gradient boosting")
model_metrics <- add_mm(cart_mod, "CART")
model_metrics <- add_mm(gbm_mod, "Stochastic gradient boosting")
model_metrics <- add_mm(knn_mod, "K-nearest neighbours")
#model_metrics <- add_mm(glm_mod, "Generalised linear regression model")
#model_metrics <- add_mm(lmt_mod,  "Robust linear model")
#model_metrics <- add_mm(rlog_mod, "Logistic model trees")

formattable(model_metrics)
```

How to read the metrics:

- R2: the higher the better (0-1)
- RMSE: the lower the better (0-inf, interpret on scale)
- MAE: the lower the better (0-inf, interpret on scale)
- MAPE: the lower the better (0-1)
- MSE: the lower the better, quite bad in all cases here

We can see that the best models appear to be the Bayesian regularised neural networks and the eXtreme gradient boosting. On some runs one has a slight edge, other times the other. Both are therefore a solid model to use for prediction, which to pick depends more on which will run better on the given hardware, as they use fairly different processing tactics.

We can see that the best models appear to be the stochastic gradient boosting and eXtreme gradient boosting. Both are therefore solid models to use for prediction, which is unsurprising, as they have quite a lot in common.

Bayesian regularised neural networks are another method that have quite high reliability.....relatively speaking, and may be a solid option when one has endless gpu power.

It seems that Poisson and CART models should not be used on our data, which proves wrong my precious though that Poisson regression looked better on the graph than linear regression. This is most likely due to the peculiarities of the Glicko rating, and the non uniform rating-bracket matches played on Lichess.

### Conclusion

Rating predictions were sadly not as accurate as I had hoped, and have much less relations to other factors than I thought, but maybe that's a peculiarity of online chess platforms where everyone can play. Furthermore, a lot of the data is qualitative, which would benefit from classification analysis and not regression.

However, the model does not do a terrible job either, as the rating pairings it suggests could still be played out at medium levels, although the lower rated player will have to use considerable brainpower to stand a chance.

I am confident that some other machine learning models such as Logistic model trees, quantile regression or even ridge / lasso / elasticnet methods would have yielded much better results, however due to some technical issues with R that I did not manage to debug, I wasn't able to run those training models.

So perhaps, with additional tuning, the linear model could be better fitted for predicting white and black ratings, however I find it unlikely that such a simple model could yield much better results, if we consider the increasing difficulty of improving one's rating at high ratings (due to how chess works), and the fact that everyone can play everyone on Lichess.

## Viking lotto

Viking Lotto was Europe's first multi-national lottery established in 1993. As of 2017, there are 9 countries participating: Denmark, Finland, Iceland, Norway, Sweden, Estonia, Latvia, Lithuania and Slovenia. Jackpots start at €3 million and can grow up to €35 million. Any more than that, and the surplus goes to lower tier prizes. Hence, there are other prizes other than the big jackpot too, but the rules and prizes vary depending on the country where the lottery is played, so the jackpot is the only steady goal. The numbers are drawn every Wednesday.

The player has to select six numbers from 1-48 and one "Viking" number from 1 to 8. To win the jackpot, all seven numbers must be matched to the lottery numbers.

### Odds of winning the jackpot | match 6 + Viking Number

First, the player needs to get 6 correct numbers out of 48. There is a chance of 1 in 12,271,512 to do this:
$$\frac{48!}{6!(48-6)!}=\frac{48!}{6!*42!}=12271512$$

Then, to get 1 correct number out of 8, the chance is evidently 1/8. The probability of winning the jackpot is thus 1 in 98,172,096.
$$\frac{1}{12271512}*\frac{1}{8}=\frac{1}{98172096}$$

### Hypergeometric distribution

Now using this formula will become tedious for further calculations, so we can use something called the [probability mass function](https://en.wikipedia.org/wiki/Hypergeometric_distribution).

$$\frac{{k \choose x}{n - k \choose k-x}}{{n \choose k}}$$
Where $n$ is the amount of possible numbers, $k$ is the number of required slots and $x$ is the number of matched numbers (observed success).

The reasoning behind this is that ${n \choose k}$ represents the total combinations, ${k \choose b}$ represents the number of winning combinations. Finally, what remains has the purpose of selecting the remaining losing numbers, thus providing the last piece of information needed to complete the combinatorial identity.

#### Function

Let's write such a function:

```{r}
dist <- function(totalNr, totalSlots, matchCount) {
  num <- choose(totalSlots, matchCount) * choose(totalNr - totalSlots, totalSlots - matchCount)
  denom <- choose(totalNr, totalSlots)
  num / denom
}
```

#### Results

```{r}
add_odd <- function(x, y) {
  dig <- 2
  odd_counts %>% add_row("Numbers matched" = paste("Match ", x, " + ", y), "Probability of winning" = dist(48, 6, x) * dist(8, 1, y))
}

odd_counts <- data.frame(matrix(ncol=1, nrow=0));
names(odd_counts) <- c("Probability of winning")
odd_counts <- rownames_to_column(odd_counts, var = "Numbers matched")

odd_counts <- add_odd(6, 1)
odd_counts <- add_odd(6, 0)
odd_counts <- add_odd(5, 1)
odd_counts <- add_odd(5, 0)
odd_counts <- add_odd(4, 1)
odd_counts <- add_odd(4, 0)
odd_counts <- add_odd(3, 1)
odd_counts <- add_odd(3, 0)

formattable(odd_counts)
```

### Conclusion

It is wise not to play lottery at all. If you do however, pick a lottery with better odds and bigger gains such as EuroJackpot, with a jackpot chance of 1 in 95,344,200. Why do people even play Viking Lotto?
