---
title: "Chess games analysis"
output: html_notebook
---

# About the dataset

The chosen dataset concerns over 20 000 games played on the popular online chess website [Lichess](https://lichess.org). It contains both qualitative and quantitative data and lends itself to many forms of analysis and study. The dataset itself comes from [kaggle](https://www.kaggle.com/datasnaek/chess).

The following variables are of use to me:

- Turns: the number of turns (double the number of moves) it took for the game to end, a quantitative variable (continuous integers)
- Victory status: the type of event that concluded the match, a qualitative variable
- Winner: the colour of the winning party, a qualitative variable
- Increment code: type of game-time incrementation used, a qualitative variable
- White/Black rating: Lichess ([Glicko-2](https://www.glicko.net/glicko/glicko2.pdf)) rating based on user's ranked game history, a quantitative variable (continuous integers)
- Opening eco: the chess opening code for a given opening, a qualitative variable
- Opening ply: the number of moves in the opening phase, a quantitative variable (continuous integers)

There are a few more variables that I have chosen to ignore:

- ID: game id in the Lichess games system/database
- Rated: boolean value describing whether the game had an impact on player rating or not
- Created/last move at: times at which a game started and when the last move was made before the game ended
- Moves: list of moves made during the game in standard chess notation, processing them could be interesting for those studying the games or players themselves
- Opening name: as I already have the more general opening code, opening names will just introduce more unique variables when factoring in variations of openings, which is harder to work with

## Initial analysis - data visualisation

To make the data-set more approachable, I conducted some visualisations to better understand the type and layout of the data I am working with. Initial visualisations can help give us clues about how to process the data later on, or what calls for further and more detailed analysis.

```{r include=FALSE}
library(ggplot2) #graphs
library(ggcorrplot)
library(tidyverse) # various tools
library(tidyr)
library(dplyr)
library(reshape2)
library(formattable)
library(ggsci) # palettes
library(caret) # required for test and training set
games <- read.csv("games.csv")
```

### Visualising the amount of turns

```{r}
ggplot(games, aes(turns)) + geom_histogram(aes(y=..density..), binwidth=15, fill="salmon1", color="black") + ggtitle("Distribution of turn counts") + xlab("Turn count") + ylab("Density of games") + geom_density(color="salmon4", alpha=.5, size=1)
```

The game turns histogram looks ordinary. It is right-skewed (positive skew) and the average turn count seems to be withing the fifties. In fact, this somewhat corresponds to data by [chessstats](https://www.chessgames.com/chessstats.html), which states that average number of moves per game is about 41, although it is still quite a bit higher.

### Visualising the ratings

As the most optimal opponent range has a rating of +/- 100 to 150, I have chosen a bin size of 100 for the ratings histogram.

```{r}
ggplot(games, aes(x=white_rating)) + geom_histogram(aes(y=..density..), binwidth=100, fill="skyblue1", color="black") + ggtitle("White rating density") + xlab("Rating") + ylab("Density of players") + geom_density(color="royalblue4", alpha=.5, size=1)
ggplot(games, aes(x=black_rating)) + geom_histogram(aes(y=..density..), binwidth=100, fill="indianred1", color="black") + ggtitle("Black rating density") + xlab("Rating") + ylab("Density of players") + geom_density(color="firebrick4", alpha=.5, size=1)
```

When a user first registers on Lichess, their rating starts at 1500 (+/- 700). The 1500 represents their rating and the 700 represents the confidence interval. This is because an average club player is rated 1500, which is around the 50th percentile for every variant and time control in chess.

It is thus unsurprising that both white and black ratings peak at around 1500. The ratings seem to be slightly right-skewed, which also makes sense, as usually the higher rated a player is, the more invested they are in the game. This in turns means that they play more and are thus more likely to be playing ranked games on Lichess.

#### Comparing the ratings

```{r}
ggplot(games) + geom_histogram(aes(x=white_rating), binwidth=100, fill="skyblue1", color="black", alpha=0.6) + geom_histogram(aes(x=black_rating), binwidth=100, fill="indianred1", color="black", alpha=0.6) + ggtitle("Comparing ratings") + xlab("Ratings") + ylab("Number of players")
```

We can see that the ratings for both white and black are mostly overlapping. This does not come as a surprise as a player should be able to play both as white and as black, and therefore would have comparable ratings for both of those colours. Interestingly enough, it would seem that there are slightly higher ratings for white, as the level of game increases, while black ratings seem to have a minimal edge for lower ranked players.

### Visualising game outcomes

```{r}
options(dplyr.summarise.inform=F)
win_counts <-group_by(games, winner) %>% summarise(Count=n()) %>% arrange(desc(Count))
ggplot(win_counts, aes(x="", y=Count, fill=winner)) + geom_bar(stat="identity", width=1, color="black") + coord_polar("y", start=0) + theme_void() + ggtitle("Game outcome") + theme(legend.title=element_blank()) + scale_fill_manual(values=c("grey21", "grey61", "grey91"))
```

The fact that white has a slightly higher probability to win a game is known as the [first move advantage](https://en.wikipedia.org/wiki/First-move_advantage_in_chess) and is most common for lower ranked players, where that advantage is harder to make up for with the lack of theoretical knowledge and experience.

I am however surprised to see that there aren't more draws, but this may be due to the fact that lower level players have less of a apacity to evaluate a board and conclude a draw.

#### Visualising game ending reasons

```{r}
options(dplyr.summarise.inform=F)
victory_status <- group_by(games, victory_status) %>% summarise(Count=n()) %>% arrange(desc(Count))
ggplot(victory_status, aes(x="", y=Count, fill=victory_status)) + geom_bar(stat="identity", width=1, color="black") + coord_polar("y", start=0) + theme_void() + ggtitle("Game end status") + theme(legend.title=element_blank()) + scale_fill_manual(values=c("skyblue1", "indianred1", "grey91", "lightsalmon1"))
```

We can see that in most cases, the game ended by resign. This is unsurprising as in chess, especially in higher levels, a player will often resign when they see that their position is irrecoverable.

It is worthy to note that games that ended due to lack of time most likely also encompass games where one player abandoned the game without resigning. Such games then ended when the timer reached 0. The basis for my reasoning is that in longer time controls, losing due to time running out is not so likely, especially if we consider the relative size to game ends by draw.

However, we could get a clearer idea of the game end statuses if we pair them with the average number of turns made in the game.

```{r}
options(dplyr.summarise.inform=F)
victory_status_avg <- group_by(games, victory_status) %>% summarise(Mean=mean(turns)) %>% arrange(desc(Mean))
ggplot(victory_status_avg, aes(x="", y=Mean, fill=victory_status)) + geom_bar(stat="identity", width=1, color="black") + coord_polar("y", start=0) + theme_void() + ggtitle("Game end status by average number of turns") + theme(legend.title=element_blank()) + scale_fill_manual(values=c("skyblue1", "indianred1", "grey91", "lightsalmon1"))
```

It would seem that as games drag out, draws become more common. This could be due to player-agreed draw, or automatic draw such as [threefold repetition](https://en.wikipedia.org/wiki/Threefold_repetition). It would also seem that losing due to time becomes also far more common, thus refuting my previous proposition that players abandoned the game but didn't resign.

#### Visualising openings

```{r}
black_wins <- subset(games, winner=="black") %>% group_by(opening_eco) %>% summarise(Count=n()) %>% arrange(desc(Count))
white_wins <- subset(games, winner=="white") %>% group_by(opening_eco) %>% summarise(Count=n()) %>% arrange(desc(Count))

white_wins$percentage <- white_wins$Count / nrow(subset(games, winner=="white"))
black_wins$percentage <- black_wins$Count / nrow(subset(games, winner=="black"))

ggplot(white_wins[1:7,], aes(x=opening_eco, y=percentage)) + geom_bar(stat = "identity") + ggtitle("Top 7 openings for white by win percent") + xlab("ECO opening code") + ylab("Percentage (out of 1)")

ggplot(black_wins[1:7,], aes(x=opening_eco, y=percentage)) + geom_bar(stat = "identity") + ggtitle("Top 7 openings for black by win percent") + xlab("ECO opening code") + ylab("Percentage (out of 1)")
```

## Quantitative overview

We can now more closely examine our quantitative variables: the amount of turns, white/black ratings, and the amount of moves in the opening phase of a game.

Helper functions:

```{r}
mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

trimean <- function(x) {
  quartiles <- quantile(x, prob=c(.25,.5,.75))
  q1 <- quartiles[1]
  q2 <- quartiles[2]
  q3 <- quartiles[3]
  (q1 + 2 * q2 + q3) / 4
}

gm_mean = function(x) {
  exp(sum(log(x[x > 0])) / length(x))
}

rel_range = function(x) {
  max(x) - min(x)
}

iqr = function(x) {
  quartiles <- quantile(x, prob=c(.25,.5,.75))
  quartiles[3] - quartiles[1]
}
```

```{r}
add_quant <- function(x, y, z) {
  dig <- 2
  x %>% add_row(Name = z, Mean = round(mean(y), digits=dig), Median = round(median(y), digits=dig), Mode = round(mode(y), digits=dig), Trimean = round(trimean(y), digits=dig), "Geometric mean" = round(gm_mean(y), digits=dig), Range = round(rel_range(y), digits=dig), IQR = round(iqr(y), digits=dig), Variance = round(var(y), digits=dig), "Standard deviation" = round(sd(y), digits=dig))
}

quant_names <- c("Mean", "Median", "Mode", "Trimean", "Geometric mean", "Range", "IQR", "Variance", "Standard deviation");

quant_overview <- data.frame(matrix(ncol=9, nrow=0));
names(quant_overview) <- quant_names
quant_overview <- rownames_to_column(quant_overview, var = "Name")

quant_overview <- add_quant(quant_overview, games$turns, "Rounds")
quant_overview <- add_quant(quant_overview, games$white_rating, "White rating")
quant_overview <- add_quant(quant_overview, games$black_rating, "Black rating")
quant_overview <- add_quant(quant_overview, games$opening_ply, "Opening moves")

formattable(quant_overview)
```

The mode tells us that the most common rating for both white and black is 1500. This makes sense as it is the default rating given to a user by Lichess upon creating an account. If a user never plays ranked matches, their rating will stay at 1500 until they play ranked matches. It seems that on average, players have slightly higher ratings as white (hence win more games as white) which again correlates to the first move advantage present in chess.

From the range we can see that there are both very highly rated players on Lichess, hence probably some international and gradnmasters, as well as players who should probably rethink their approach to playing and studying chess, as their low ratings point to them losing most of the games they play against opponents of presumably comparable ratings.

The standard deviation is not very high either if we factor in the nature of the Glicko scale, and how easy it is to move up or down in ratings within the 1200-1700 rating range, after first joining Lichess (due to off-platform proficiency). It would seem that the average player is however rated slightlty more than the Lichess default of 1500, and player ratings do not deviate remarkably far from that average.

We can see that half of games played aren't longer than 55 turns, with the most games lasting for 53 turns. Interestingly, the average number of turns of a game is 60.47 which would suggest that there is a non negligible amount of games that dragged on for large numbers of turns.

While in chess the shortest mates are the [Fool's Mate](https://en.wikipedia.org/wiki/Fool%27s_mate) (2 turns) and the [Scholar's Mate](https://en.wikipedia.org/wiki/Scholar%27s_mate) (4 turns), a game can of course consist of only one turn in case of running out of time, or an immediate resign. As the range of turns is 348, we can deduce that there is at least one game with 349 turns, which solidifies our previous theory of some games reaching high turn counts.

Concerning the opening moves, it seems that on average, almost 5 moves are played by the book, but most commonly, no more than 3 moves are from book opening variations. It is a bit surprising that the number is so low, as most opening theory covers way more moves, but as there aren't only club/pro players on Lichess, it makes sense that standard openings aren't followed by the book as often. The standard deviation is not very high, showing that most games fall have opening falls within three moves of the average number of moves in the opening phase.

In conclusion we can say that the Lichess games data set is not very surprising, if one factors in the fact that both hobby or even rookie players, and club or even master players can be found on the platform. Of course such mishmash will provide deviations from chess statistics from tournament and club games, but it's a wonderful way to show the broad appeal and various approaches that the game has.

The quantitative overview of variables corresponds very well to the initial visualisations of the data set, with no devaitions worthy of concern.

## Examining relationships

From what we saw from the initial visualisation stage, we can assume that white and black ratings are somewhat related to each other. Furthermore, it seems logical that the opening and the number of moves in the opening phase would have at least minor correlations due to the length, popularity and variation count factors of openings. Finally we can also suppose that the qualitative id's for white and black have some form of relationship as we can expect players to replay each-other a number of times.

It would be interesting to see if players of certain ratings have a preference for the games' time control, and if the opening favors a side in winning (consistency with opening book theory).

### Correlation matrices

```{r}
char2num<-function(x) { 
  groups = unique(x) 
  as.numeric(factor(x, levels=groups)) 
}

matrix_data <- subset(games, select = c(turns, white_rating, black_rating, opening_eco, opening_ply, increment_code, winner, white_id, black_id))
matrix_data$opening_eco <- char2num(matrix_data$opening_eco)
matrix_data$increment_code <- char2num(matrix_data$increment_code)
matrix_data$winner <- char2num(matrix_data$winner)
matrix_data$white_id <- char2num(matrix_data$white_id)
matrix_data$black_id <- char2num(matrix_data$black_id)

corr <- cor(matrix_data)
ggcorrplot(corr, lab=T)
```

#### How to read the correlation matrix

The above correlation matrix gives us Pearson correlation coefficients, which is a way to measure the linear relationship between two variables. This value appears in the interval [-1;1], where the further the coefficient is from 0, the stronger the relationship between variables is. A positive coefficient indicates a positive correlation, and vice versa for a negative coefficient.

#### Notable correlations

We can see that white's and black's rating seems to be in correlation, which confirms what we saw from our initial visualisations. Indeed, players of similar ratings are paired together for random ranked games on Lichess. While the correlation is not as strong as I would have expected, I suspect that the reason for this is that a player can still play another player of any ranking, as there are no rules determining the maximum rating gap between players.

Furthermore, black's and white's id's have a very strong correlation, which confirms that many players tend to play more than one game against one another. However, as those are qualitative variables, it is difficult to visualise their relationship on a graph, instead, a contingency table should be used.

Finally, we can see a non negligible correlation between the chosen opening and the number of moves played in the opening phase. Likewise, as these variables are qualitative, visualising them on a graph is not feasible.

I am somewhat surprised that there seems to be a total absence of correlation between the number of turns and the opening, as some openings are more aggressive/sharp, while others are more passive, potentially leading to slow and complex middle- and endgames.

### Dependent and independent variable relationships

#### White and black ratings

```{r}
ratings_matrix <- subset(games, select = c(white_rating, black_rating))
ggplot(ratings_matrix, aes(x=white_rating, y=black_rating)) + geom_point(color="royalblue4") + ggtitle("Relationship of white and black ratings") + xlab("White rating") + ylab("Black rating")
```

### Regression model

Since there is only one quantitative linear correlation, I will have to work with the white and black ratings relationship.

To avoid overplotting, I round the ratings to the nearest multiple of 25, which isn't a huge gap to close for players with ratings lower than 2200. Players above that are scarcer in any case, and their games are less likely to be against opponents of same ratings on Lichess.

```{r}
ratings_matrix$white_rating <- round(ratings_matrix$white_rating/25)*25
ratings_matrix$black_rating <- round(ratings_matrix$black_rating/25)*25
ggplot(ratings_matrix, aes(x=white_rating, y=black_rating)) + geom_point(alpha=1/4, color="royalblue4") + ggtitle("Linear relationship of ratings") + xlab("White rating") + ylab("Black rating") + geom_smooth(method="lm", formula=y~x, color="firebrick1")
```

## Training and testing regression models

### Choosing and splitting the dataset

I have chosen to train the model on 80% of of the data set, which leaves 20% for testing.

```{r}
relevant_data <- subset(games, select = c(white_rating, black_rating))
sample <- createDataPartition(relevant_data$white_rating, p=.8, list=F)
training <- relevant_data[sample,]
testing <- relevant_data[-sample,]

set.seed(123)
# Linear regression model
lm_mod <- train(white_rating ~ ., data=training, method="lm")
# Generalised linear model
glm_mod <- train(white_rating ~ ., data=training, method="glm")
# k-nearest neighbors
knn_mod <- train(white_rating ~ ., data=training, method="knn")
# Robust linear model
rlm_mod <- train(white_rating ~ ., data=training, method="rlm")
# Quantile regression neuiral network
#qrnn_mod <- train(white_rating ~ ., data=training, method="qrnn")
# Neural net
neural_mod <- train(white_rating ~ ., data=training, method="neuralnet")
# Lasso
#lasso_mod <- train(white_rating ~ ., data=training, method="lasso")
# Ridge regression
#ridge_mod <- train(white_rating ~ ., data=training, method="ridge")
# Elasticnet
#enet_mod <- train(white_rating ~ ., data=training, method="enet")
```